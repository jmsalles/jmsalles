# üß© Guia completo ‚Äî Monitorar Kubernetes ‚Äúpuro‚Äù (kubeadm) no Zabbix 7.4

> üéØ **Objetivo:** coletar estado do **cluster**, **n√≥s**, **kubelet** e **control plane** via templates oficiais ‚Äúby HTTP‚Äù, usando **ServiceAccount + RBAC**, **token** longa dura√ß√£o e **descobertas (LLD)** que criam os hosts automaticamente.

---

## üìå Resumo

* Criaremos **ServiceAccount** e **RBAC** m√≠nimos para leitura.
* Emitiremos **token** de longa dura√ß√£o (lab).
* No Zabbix, criaremos 2 **hosts base** (dummy) e vincularemos os **templates de Kubernetes**.
* Ajustaremos **macros** (‚ö†Ô∏è **sem `/api`** no macro de URL).
* For√ßaremos a **LLD** (‚ÄúCheck now‚Äù), validaremos dados e afinaremos ru√≠do.
* Incluo **dashboard**, **notifica√ß√µes** e **troubleshooting** (ex.: n√≥ NotReady).

---

## üìö Sum√°rio

* [Topologia do ambiente](#topologia-do-ambiente)
* [O que ser√° monitorado (vis√£o geral)](#o-que-ser√°-monitorado-vis√£o-geral)
* [Pr√©-requisitos r√°pidos](#pr√©-requisitos-r√°pidos)
* [1) RBAC: ServiceAccount + permiss√µes](#1-rbac-serviceaccount--permiss√µes)
* [2) Token longa dura√ß√£o e testes de API](#2-token-longa-dura√ß√£o-e-testes-de-api)
* [3) Zabbix: hosts base, templates e macros](#3-zabbix-hosts-base-templates-e-macros)
* [4) For√ßar a descoberta (LLD) e validar](#4-for√ßar-a-descoberta-lld-e-validar)
* [5) Ajustes √∫teis (ru√≠do, dashboard, notifica√ß√µes)](#5-ajustes-√∫teis-ru√≠do-dashboard-notifica√ß√µes)
* [6) Troubleshooting (erros comuns)](#6-troubleshooting-erros-comuns)
* [FAQ](#faq)
* [Checklist final](#checklist-final)
* [Refer√™ncias r√°pidas](#refer√™ncias-r√°pidas)

---

## Topologia do ambiente

* **Cluster kubeadm v1.30.14**
* **N√≥s**

  * `k8s-cp1` ‚Äî 192.168.31.40 (control-plane)
  * `k8s-w1` ‚Äî 192.168.31.41 (worker)
  * `k8s-w2` ‚Äî 192.168.31.42 (worker)
* **SO**: Rocky Linux 10 nos tr√™s
* **Zabbix 7.4** (Server + Frontend)
* **Zabbix agent** j√° instalado nos n√≥s

---

## O que ser√° monitorado (vis√£o geral)

| Componente          | Itens/alertas principais                                                                                                                       |
| ------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| **Cluster/Objetos** | Pods `Pending`, `CrashLoopBackOff`, `Restarts` elevados; Deployments abaixo do desired; Jobs/CronJobs falhando; Namespaces; Services/Endpoints |
| **Control plane**   | Sa√∫de do API Server, Scheduler, Controller-Manager (`/readyz`/`/healthz`)                                                                      |
| **N√≥ (Node)**       | Condi√ß√µes (`Ready`, `MemoryPressure`, `DiskPressure`, etc.), capacidade/allocatable, contagem de pods                                          |
| **Kubelet**         | Coleta via HTTP proxy pelo API server (sem abrir porta 10250 externamente)                                                                     |
| **Sistema (Linux)** | CPU, RAM, FS, rede via ‚ÄúLinux by Zabbix agent‚Äù (aplicado automaticamente aos n√≥s descobertos)                                                  |

---

## Pr√©-requisitos r√°pidos

* `kubectl` funcional no `k8s-cp1` (ou em qualquer host com acesso ao API).
* Zabbix Server alcan√ßa `https://192.168.31.40:6443` pela rede.
* `firewalld` **desativado** ou regra liberada (no seu ambiente est√° inativo).

```bash
kubectl version
kubectl cluster-info
kubectl get nodes -o wide
```

---

## 1) RBAC: ServiceAccount + permiss√µes

Crie namespace, ServiceAccount e **ClusterRole/Binding** com leitura m√≠nima (inclui `nodes`, recursos core e apps/batch, EndpointSlices, Ingress e metrics.k8s.io opcional).

```bash
vim zbx-rbac.yaml
```

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: zabbix-service-account
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: zabbix-k8s-read
rules:
  - apiGroups: [""]
    resources: [nodes,namespaces,pods,services,endpoints,persistentvolumeclaims,persistentvolumes,events]
    verbs: [get,list,watch]
  - apiGroups: ["apps"]
    resources: [deployments,daemonsets,statefulsets,replicasets]
    verbs: [get,list,watch]
  - apiGroups: ["batch"]
    resources: [jobs,cronjobs]
    verbs: [get,list,watch]
  - apiGroups: ["discovery.k8s.io"]
    resources: [endpointslices]
    verbs: [get,list,watch]
  - apiGroups: ["networking.k8s.io"]
    resources: [ingresses]
    verbs: [get,list,watch]
  - apiGroups: ["metrics.k8s.io"]
    resources: [nodes,pods]
    verbs: [get,list,watch]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: zabbix-k8s-read-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: zabbix-k8s-read
subjects:
  - kind: ServiceAccount
    name: zabbix-service-account
    namespace: monitoring
```

```bash
kubectl apply -f zbx-rbac.yaml
kubectl auth can-i get nodes --as=system:serviceaccount:monitoring:zabbix-service-account
kubectl auth can-i list pods -A --as=system:serviceaccount:monitoring:zabbix-service-account
```

*Ambos devem responder `yes`.*

---

## 2) Token longa dura√ß√£o e testes de API

Gere token **v√°lido por 1 ano** (laborat√≥rio):

```bash
kubectl -n monitoring create token zabbix-service-account --duration=8760h > /tmp/kube.zbx.token
export TOKEN=$(cat /tmp/kube.zbx.token)
```

Teste **endpoint base** e **nodes**:

```bash
curl -sk -H "Authorization: Bearer $TOKEN" https://192.168.31.40:6443/api | jq .
curl -sk -H "Authorization: Bearer $TOKEN" https://192.168.31.40:6443/api/v1/nodes | jq .
```

Se listar os n√≥s, **RBAC + token + API** est√£o ok.

---

## 3) Zabbix: hosts base, templates e macros

> Os templates ‚ÄúKubernetes ‚Ä¶ by HTTP‚Äù usam **hosts base** (dummy) para guardar macros e executar a LLD. Eles **criam** automaticamente os hosts reais (n√≥s e componentes) e aplicam ‚ÄúLinux by Zabbix agent‚Äù.

### 3.1) Templates a usar (Zabbix 7.4)

* **Kubernetes nodes by HTTP**
* **Kubernetes cluster state by HTTP**
  *(Os de API Server/Scheduler/Controller-Manager/Kubelet ser√£o aplicados automaticamente √†s entidades descobertas.)*

### 3.2) Criar hosts base (dummy)

Crie **dois hosts** (nomes sugeridos; use os seus se preferir):

* **Host:** `k8s-nodes`

  * **Interface:** Agent `127.0.0.1` (dummy)
  * **Template:** `Kubernetes nodes by HTTP`

* **Host:** `k8s-cluster-state`

  * **Interface:** Agent `127.0.0.1` (dummy)
  * **Template:** `Kubernetes cluster state by HTTP`

### 3.3) **Macros (importante!)**

‚ö†Ô∏è **N√£o adicione `/api` no macro de URL** se a descri√ß√£o do seu template indicar formato `<scheme>://<host>:<port>`. O template monta os caminhos internamente.

No **`k8s-nodes`** **e** no **`k8s-cluster-state`**:

* `{$KUBE.API.URL}` = `https://192.168.31.40:6443`  *(base sem `/api`)*
* `{$KUBE.API.TOKEN}` = **cole o conte√∫do de** `/tmp/kube.zbx.token`

> Dica: em **Host ‚Üí Macros ‚Üí ‚ÄúInherited and host macros‚Äù** verifique o valor efetivo.

---

## 4) For√ßar a descoberta (LLD) e validar

### 4.1) ‚ÄúCheck now‚Äù nas regras de LLD

No Zabbix Frontend:

* **Configuration ‚Üí Hosts ‚Üí `k8s-nodes` ‚Üí aba ‚ÄúDiscovery rules‚Äù ‚Üí** clique **Check now** na regra (ex.: ‚ÄúKubernetes nodes: discovery‚Äù).
* **Configuration ‚Üí Hosts ‚Üí `k8s-cluster-state` ‚Üí aba ‚ÄúDiscovery rules‚Äù ‚Üí** **Check now** nas regras de cluster/componentes.

> Para acelerar, voc√™ pode recarregar o cache de config do Server:

```bash
sudo -u zabbix zabbix_server -R config_cache_reload
```

### 4.2) Validar

* **Configuration ‚Üí Hosts**: devem surgir **`k8s-cp1`**, **`k8s-w1`**, **`k8s-w2`** (normalmente j√° com **Linux by Zabbix agent** linkado).
  Ajuste a **interface/IP** de cada host para o IP real.

```bash
zabbix_get -s 192.168.31.40 -k agent.ping
zabbix_get -s 192.168.31.41 -k agent.ping
zabbix_get -s 192.168.31.42 -k agent.ping
```

* **Monitoring ‚Üí Latest data**: devem aparecer itens de **nodes/pods/deployments/jobs**.

### 4.3) (Opcional) Item HTTP de teste (sanidade)

```bash
# No host base "k8s-nodes", crie:
# Type: HTTP agent
# Name: TEST /api/v1/nodes
# URL:  {$KUBE.API.URL}/api/v1/nodes
# Header: Authorization: Bearer {$KUBE.API.TOKEN}
# Verify peer/host: No
```

Se esse item retorna JSON, o token/macro est√£o corretos.

---

## 5) Ajustes √∫teis (ru√≠do, dashboard, notifica√ß√µes)

### 5.1) Filtrar ru√≠do por namespace (LLD)

Em **k8s-cluster-state ‚Üí Discovery rules**, abra as regras de pods/deployments e inclua um **Filter** por `{#NAMESPACE}`:

```
^(kube-system|default|ingress-nginx)$
```

*(Depois amplie conforme for instalando componentes.)*

### 5.2) Dashboard r√°pido

* **Monitoring ‚Üí Dashboards ‚Üí Create** (‚ÄúK8s ‚Äî Vis√£o Geral‚Äù)

  * **Problems** (Group = Kubernetes)
  * **Top** ‚Üí ‚ÄúPods com mais Restarts‚Äù
  * **Top** ‚Üí ‚ÄúNodes NotReady (√∫ltimas 3h)‚Äù
  * **Graph (classic)** ‚Üí itens do `k8s-cluster-state` (ex.: ‚ÄúPods por fase‚Äù, ‚ÄúDeployments sem r√©plicas desejadas‚Äù)

### 5.3) Notifica√ß√µes

Crie **Action** para severidades *High/Critical* com condi√ß√£o **Group = Kubernetes** (ou Tag = kubernetes) e envie para seu e-mail/Teams.

---

## 6) Troubleshooting (erros comuns)

### 6.1) 403 ‚Äúcannot get resource ‚Äòv1‚Äô‚Ä¶‚Äù

* Macro de URL com `/api` por engano.
  **Fix:** `{$KUBE.API.URL} = https://192.168.31.40:6443` (sem `/api`).
* Token expirado: gere novo e cole na macro.

```bash
kubectl -n monitoring create token zabbix-service-account --duration=8760h > /tmp/kube.zbx.token
```

### 6.2) LLD n√£o cria nada

* **Check now** na LLD e veja ‚ÄúShow latest error‚Äù.
* Verifique **RBAC**:

```bash
kubectl auth can-i get nodes --as=system:serviceaccount:monitoring:zabbix-service-account
kubectl auth can-i list pods -A --as=system:serviceaccount:monitoring:zabbix-service-account
```

* Teste API com `curl` (URL/macro + token):

```bash
curl -sk -H "Authorization: Bearer $TOKEN" https://192.168.31.40:6443/api | jq .
curl -sk -H "Authorization: Bearer $TOKEN" https://192.168.31.40:6443/api/v1/nodes | jq .
```

### 6.3) N√≥ `NotReady`

No n√≥ afetado (ex.: `k8s-w2`):

```bash
kubectl describe node k8s-w2 | sed -n '1,200p'
kubectl -n kube-system get pods -o wide
sudo journalctl -u kubelet -b --no-pager | tail -n 200
```

Ajustes comuns (containerd + cgroup + sysctl):

```bash
# containerd: habilitar SystemdCgroup=true
sudo test -f /etc/containerd/config.toml || sudo containerd config default | sudo tee /etc/containerd/config.toml >/dev/null
sudo vim /etc/containerd/config.toml
# [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
# SystemdCgroup = true
sudo systemctl restart containerd kubelet

# sysctl p/ rede
sudo bash -lc 'cat >/etc/sysctl.d/99-k8s.conf <<EOF
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF'
sudo sysctl --system

# swap off
sudo swapoff -a
sudo sed -r -i 's/^([^#].*\sswap\s)/#\1/' /etc/fstab
sudo systemctl restart kubelet
```

### 6.4) TLS/Certificados

Para teste use `-k` no `curl`. Em produ√ß√£o, importe a CA do cluster no host do Zabbix (ou habilite verifica√ß√£o nos itens HTTP).

---

## FAQ

**Posso usar Zabbix Proxy dentro do cluster?**
Sim. Ajuda a reduzir lat√™ncia/tr√°fego e estabiliza a LLD. Pode ser instalado via **Helm**.

**Preciso abrir a porta 10250 (kubelet)?**
N√£o. O template ‚ÄúKubelet by HTTP‚Äù acessa via **proxy do API server** usando o mesmo token.

**Quero `kubectl top`/m√©tricas.**
Instale **metrics-server**; os templates funcionam sem ele, mas o `top` e m√©tricas k8s.io ficam dispon√≠veis.

---

## Checklist final

* [ ] RBAC aplicado (`zabbix-k8s-read` + binding)
* [ ] `kubectl auth can-i get/list nodes` = **yes**
* [ ] Token criado com `--duration=8760h` e **colado** nas macros
* [ ] **Hosts base** criados: `k8s-nodes` (Nodes by HTTP) e `k8s-cluster-state` (Cluster state by HTTP)
* [ ] **Macros**: `{$KUBE.API.URL}=https://192.168.31.40:6443` (‚ö†Ô∏è sem `/api`) + `{$KUBE.API.TOKEN}`
* [ ] **LLD**: ‚ÄúCheck now‚Äù executado sem erros
* [ ] Hosts dos n√≥s (`k8s-cp1`, `k8s-w1`, `k8s-w2`) criados com **Linux by Zabbix agent**
* [ ] Dashboard com **Problems/Top/Graph (classic)**
* [ ] Action de **notifica√ß√µes** ativa

---

## Refer√™ncias r√°pidas

```bash
# Ver vers√£o/sa√∫de/states
kubectl version
kubectl cluster-info
kubectl get nodes -o wide

# RBAC (valida√ß√£o r√°pida)
kubectl auth can-i get nodes --as=system:serviceaccount:monitoring:zabbix-service-account
kubectl auth can-i list pods -A --as=system:serviceaccount:monitoring:zabbix-service-account

# Token (1 ano)
kubectl -n monitoring create token zabbix-service-account --duration=8760h > /tmp/kube.zbx.token
export TOKEN=$(cat /tmp/kube.zbx.token)

# Teste API
curl -sk -H "Authorization: Bearer $TOKEN" https://192.168.31.40:6443/api | jq .
curl -sk -H "Authorization: Bearer $TOKEN" https://192.168.31.40:6443/api/v1/nodes | jq .

# For√ßar LLD e recarregar config
sudo -u zabbix zabbix_server -R config_cache_reload

# Sanidade do agent
zabbix_get -s 192.168.31.40 -k agent.ping
zabbix_get -s 192.168.31.41 -k agent.ping
zabbix_get -s 192.168.31.42 -k agent.ping
```

---

**Criado por Jeferson Salles**
LinkedIn: [https://www.linkedin.com/in/jmsalles/](https://www.linkedin.com/in/jmsalles/)
E-mail: [jefersonmattossalles@gmail.com](mailto:jefersonmattossalles@gmail.com).
